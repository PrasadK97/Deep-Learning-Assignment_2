{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k15O2kcKdpa1"
      },
      "outputs": [],
      "source": [
        "#Import and install required libraries\n",
        "import os\n",
        "import glob\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Activation, Dropout, BatchNormalization\n",
        "import numpy as np\n",
        "\n",
        "!pip install wandb\n",
        "import wandb\n",
        "from wandb.keras import WandbCallback\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'svg'\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "IK4BuoHudqIN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Unzip and load file data file onto server, then delete zip file for optimizing performance\n",
        "zip_path = \"drive/MyDrive/nature_12K.zip\"\n",
        "!cp \"{zip_path}\" .\n",
        "!unzip -q nature_12K.zip\n",
        "!rm nature_12K.zip"
      ],
      "metadata": {
        "id": "GBQl-DEXdqMd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Automate the building of CNN\n",
        "def createCNN(num_filters=32, filter_multiplier=1, dropout=0.2, batch_norm=False, dense_size=64, num_classes=10, image_size=200):\n",
        "    model = Sequential()\n",
        "\n",
        "    for i in range(5):\n",
        "        filter_dim = 11 - 2*i\n",
        "        filter_size = (filter_dim, filter_dim)\n",
        "        if i==0:\n",
        "            model.add(Conv2D(num_filters, filter_size, input_shape=(image_size, image_size, 3), data_format=\"channels_last\"))\n",
        "        else:\n",
        "            model.add(Conv2D(num_filters, filter_size))\n",
        "        if batch_norm:\n",
        "            model.add(BatchNormalization())\n",
        "        model.add(Activation(\"relu\"))\n",
        "        model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "        num_filters = int(num_filters * filter_multiplier)\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(dense_size))\n",
        "    model.add(Dropout(dropout))\n",
        "    model.add(Activation(\"relu\"))\n",
        "    model.add(Dense(num_classes))\n",
        "    model.add(Activation(\"softmax\"))\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "666cEUi5dqOq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Prepare the dataset for training\n",
        "def prepare_dataset(DATA_DIR=\"inaturalist_12K\", augment_data=False):\n",
        "    train_dir = os.path.join(DATA_DIR, \"train\")\n",
        "    test_dir = os.path.join(DATA_DIR, \"val\")\n",
        "\n",
        "    if augment_data:\n",
        "        train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                          rotation_range=90,\n",
        "                                          zoom_range=0.2,\n",
        "                                          shear_range=0.2,\n",
        "                                          validation_split=0.1,\n",
        "                                          horizontal_flip=True)\n",
        "        test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "    else:\n",
        "        train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.1)\n",
        "        test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "    train_generator = train_datagen.flow_from_directory(train_dir, target_size=(200, 200), batch_size=256, subset=\"training\")\n",
        "    val_generator = train_datagen.flow_from_directory(train_dir, target_size=(200, 200), batch_size=256, subset=\"validation\")\n",
        "    test_generator = test_datagen.flow_from_directory(test_dir, target_size=(200, 200), batch_size=256)\n",
        "\n",
        "    return train_generator, val_generator, test_generator;"
      ],
      "metadata": {
        "id": "1oj8QqKadqQy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Customise run names for WandB to enhance readability\n",
        "def setRunName(num_filters=32, filter_multiplier=1, augment_data=False, dropout=0.2, batch_norm=False):\n",
        "\n",
        "    augment_data_options = {True: \"Y\", False: \"N\"}\n",
        "    batch_norm_options = {True: \"Y\", False: \"N\"}\n",
        "\n",
        "    run_name = \"_\".join([\"num\", str(num_filters), \"org\", str(filter_multiplier), \"aug\", augment_data_options[augment_data],\n",
        "                      \"drop\", str(dropout), \"norm\", batch_norm_options[batch_norm]])\n",
        "\n",
        "    return run_name;"
      ],
      "metadata": {
        "id": "uMhucdqFdqS-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Integrate WandB with training and validation process\n",
        "def train():\n",
        "\n",
        "    config_defaults = {\n",
        "        \"num_filters\": 32,\n",
        "        \"filter_multiplier\": 2,\n",
        "        \"augment_data\": False,\n",
        "        \"dropout\": 0.3,\n",
        "        \"batch_norm\": False,\n",
        "        \"epochs\": 10,\n",
        "        \"dense_size\": 64,\n",
        "        \"lr\": 0.001\n",
        "    }\n",
        "\n",
        "    wandb.init(config=config_defaults, magic=True)\n",
        "    config = wandb.config\n",
        "    wandb.run.name = setRunName(config.num_filters, config.filter_multiplier, config.augment_data, config.dropout, config.batch_norm)\n",
        "\n",
        "    train_generator, val_generator, test_generator = prepare_dataset(augment_data=config.augment_data)\n",
        "    model = createCNN(num_filters=config.num_filters, filter_multiplier=config.filter_multiplier,\n",
        "                      dropout=config.dropout, batch_norm=config.batch_norm, dense_size=config.dense_size)\n",
        "    model.compile(optimizer=keras.optimizers.Adam(config.lr), loss=\"categorical_crossentropy\", metrics=\"categorical_accuracy\")\n",
        "    model.fit(train_generator, epochs=config.epochs, validation_data=val_generator, callbacks=[WandbCallback()])"
      ],
      "metadata": {
        "id": "cr2_i1ySdqUx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Prepare training and test generators for testing\n",
        "def prepare_test_dataset(DATA_DIR=\"inaturalist_12K\", augment_data=False, image_size=200):\n",
        "    train_dir = os.path.join(DATA_DIR, \"train\")\n",
        "    test_dir = os.path.join(DATA_DIR, \"val\")\n",
        "\n",
        "    if augment_data:\n",
        "        train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                          rotation_range=90,\n",
        "                                          zoom_range=0.2,\n",
        "                                          shear_range=0.2,\n",
        "                                          horizontal_flip=True)\n",
        "        test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "    else:\n",
        "        train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "        test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "    train_generator = train_datagen.flow_from_directory(train_dir, target_size=(image_size, image_size), batch_size=256)\n",
        "    test_generator = test_datagen.flow_from_directory(test_dir, target_size=(image_size, image_size), batch_size=30)\n",
        "\n",
        "    return train_generator, test_generator;\n",
        "\n",
        "#Display sample test images with their predictions and labels\n",
        "def plot_test_results(test_data, predictions, labels):\n",
        "    fig, ax = plt.subplots(nrows=5, ncols=6, figsize=(15,15))\n",
        "    output_map = {0: 'Amphibia', 1: 'Animalia', 2: 'Arachnida', 3: 'Aves', 4: 'Fungi',\n",
        "                  5: 'Insecta', 6: 'Mammalia', 7: 'Mollusca', 8: 'Plantae', 9: 'Reptilia'}\n",
        "    for i in range(30):\n",
        "        img = test_data[0][0][i]\n",
        "        ax[int(i/6), i%6].imshow(img)\n",
        "        ax[int(i/6), i%6].axis('off')\n",
        "        ax[int(i/6), i%6].set_aspect('equal')\n",
        "\n",
        "        ax[int(i/6), i%6].set_title(\"Predicted: \" + output_map[np.argmax(predictions, axis=1)[i]] + \"\\nLabel: \" + output_map[np.argmax(labels, axis=1)[i]])\n",
        "\n",
        "#Visualise feature maps from the first Conv layer for a test image\n",
        "\n",
        "\n",
        "def plot_filters(model, test_data, sample_num):\n",
        "    sub_model = Model(inputs=model.inputs, outputs=model.layers[1].output)\n",
        "    plt.imshow(test_data[0][0][sample_num])\n",
        "    plt.axis('off')\n",
        "    feature_maps = sub_model(test_data[0][0])\n",
        "    fig, ax = plt.subplots(4, 8, figsize=(12,6))\n",
        "    for i in range(feature_maps.shape[-1]):\n",
        "        ax[int(i/8), i%8].imshow(feature_maps[sample_num, :, :, i], cmap='gray')\n",
        "        ax[int(i/8), i%8].axis('off')"
      ],
      "metadata": {
        "id": "JBKxVWx0dqXD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Integrate WandB with testing and evaluation process\n",
        "def test():\n",
        "\n",
        "    config_defaults = {\n",
        "        \"num_filters\": 32,\n",
        "        \"filter_multiplier\": 2,\n",
        "        \"augment_data\": True,\n",
        "        \"dropout\": 0.3,\n",
        "        \"batch_norm\": True,\n",
        "        \"epochs\": 10,\n",
        "        \"dense_size\": 64,\n",
        "        \"lr\": 0.001\n",
        "    }\n",
        "\n",
        "    wandb.init(config=config_defaults, magic=True)\n",
        "    config = wandb.config\n",
        "    wandb.run.name = setRunName(config.num_filters, config.filter_multiplier, config.augment_data, config.dropout, config.batch_norm)\n",
        "\n",
        "    train_generator, test_generator = prepare_test_dataset(augment_data=config.augment_data, image_size=256)\n",
        "    model = createCNN(num_filters=config.num_filters, filter_multiplier=config.filter_multiplier,\n",
        "                      dropout=config.dropout, batch_norm=config.batch_norm, dense_size=config.dense_size, image_size=256)\n",
        "    model.compile(optimizer=keras.optimizers.Adam(config.lr), loss=\"categorical_crossentropy\", metrics=\"categorical_accuracy\")\n",
        "    model.fit(train_generator, epochs=config.epochs, callbacks=[WandbCallback()])\n",
        "\n",
        "    print(\"Evaluating Model:\")\n",
        "    model.evaluate(test_generator, batch_size=256)\n",
        "    predictions = model(test_generator[0][0])\n",
        "    plot_test_results(test_generator, predictions, test_generator[0][1])\n",
        "    sample_num = 11\n",
        "    plot_filters(model, test_generator, sample_num)\n",
        "    model.save(\"Best_model.h5\")"
      ],
      "metadata": {
        "id": "-TjtEYfcdqZA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Set up a sweep config\n",
        "sweep_config = {\n",
        "    \"name\": \"Test and Save Best Model Again\",\n",
        "    \"description\": \"Checking the performance of CNN on sample of test data\",\n",
        "    \"metric\": \"Val Accuracy\",\n",
        "    \"method\": \"grid\",\n",
        "    \"project\": \"CS6910_Assignment2\",\n",
        "    \"parameters\": {\n",
        "        \"num_filters\": {\n",
        "            \"values\": [32]\n",
        "        },\n",
        "        \"filter_multiplier\": {\n",
        "            \"values\": [2]\n",
        "        },\n",
        "        \"augment_data\": {\n",
        "            \"values\": [True]\n",
        "        },\n",
        "        \"dropout\": {\n",
        "            \"values\": [0.3]\n",
        "        },\n",
        "        \"batch_norm\": {\n",
        "            \"values\": [True]\n",
        "        },\n",
        "        \"epochs\": {\n",
        "            \"values\": [1]\n",
        "        },\n",
        "        \"dense_size\": {\n",
        "            \"values\": [64]\n",
        "        },\n",
        "        \"lr\": {\n",
        "            \"values\": [0.001]\n",
        "        },\n",
        "        \"epochs\": {\n",
        "            \"values\": [10]\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "# creating the sweep\n",
        "sweep_id = wandb.sweep(sweep_config, project=\"CS6910_Assignment2\")"
      ],
      "metadata": {
        "id": "xpDzJpcGdqbW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.agent(sweep_id, function=test)"
      ],
      "metadata": {
        "id": "AkZ-GALfdqdh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}