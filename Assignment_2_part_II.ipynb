{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZXnIymGEeVX9"
      },
      "outputs": [],
      "source": [
        "# import necessary libraries\n",
        "import os\n",
        "import glob\n",
        "import wandb\n",
        "from wandb.keras import WandbCallback\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'svg'\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(input_shape=(256,256)):\n",
        "    \"\"\"Loads the data and performs preprocessing\n",
        "\n",
        "    Args:\n",
        "        input_shape (tuple, optional): shape to resize all images to. Defaults to (256,256).\n",
        "\n",
        "    Returns:\n",
        "        tuple: train dataset, validation dataset\n",
        "    \"\"\"\n",
        "\n",
        "    DATA_DIR = r\"/content/drive/MyDrive/inaturalist_12K\"\n",
        "\n",
        "    train_dir = os.path.join(DATA_DIR, \"train\")\n",
        "    val_dir = os.path.join(DATA_DIR, \"val\")\n",
        "\n",
        "    train_generator = ImageDataGenerator(rescale=1./255,\n",
        "                                    rotation_range=50,\n",
        "                                    zoom_range=0.2,\n",
        "                                    shear_range=0.2,\n",
        "                                    horizontal_flip=True)\n",
        "    val_generator =ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "    train_ds = train_generator.flow_from_directory(train_dir, target_size=input_shape, batch_size=128, shuffle=True)\n",
        "    val_ds = val_generator.flow_from_directory(val_dir, target_size=input_shape, batch_size=128)\n",
        "\n",
        "    return train_ds, val_ds\n",
        "\n",
        "# testing out the function\n",
        "train_ds, val_ds = load_data()\n",
        ""
      ],
      "metadata": {
        "id": "iM2TFVvJeXKF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Utility functions for plotting ##\n",
        "def plot_sample_images(dir_path):\n",
        "    \"\"\"Plots one sample from each label\n",
        "\n",
        "    Args:\n",
        "        dir_path (str): path of the directory containing the images\n",
        "    \"\"\"\n",
        "\n",
        "    subdirs = glob.glob(os.path.join(dir_path,r\"*\"))\n",
        "\n",
        "    fig_height = len(subdirs)//5\n",
        "\n",
        "    if len(subdirs)%5 != 0:\n",
        "        fig_height+=1\n",
        "\n",
        "    fig, axs = plt.subplots(fig_height, 5, figsize=(10, fig_height*2))\n",
        "    fig.suptitle(\"Sample images from each class\")\n",
        "    axs = axs.reshape(-1)\n",
        "\n",
        "    for i, subdir in enumerate(subdirs):\n",
        "\n",
        "        class_name = os.path.basename(subdir)\n",
        "        axs[i].set_title(class_name)\n",
        "\n",
        "        img_path = glob.glob(os.path.join(subdir, r\"*\"))[0]\n",
        "        img = mpimg.imread(img_path)\n",
        "        axs[i].imshow(img)\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "9ljWhkCdeXL3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting samples using the above function\n",
        "DATA_DIR = r\"/content/drive/MyDrive/inaturalist_12K\"\n",
        "plot_sample_images(os.path.join(DATA_DIR,\"train\"))\n",
        ""
      ],
      "metadata": {
        "id": "hpdcSjYGeXOA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNet(tf.keras.Model):\n",
        "    \"\"\"This class holds the model for training\n",
        "    \"\"\"\n",
        "    def __init__(self, base_model, image_shape=(256, 256)):\n",
        "        \"\"\"Init function\n",
        "\n",
        "        Args:\n",
        "            base_model (str): The base pretrained model to use\n",
        "            image_shape (tuple, optional): image shape as input for the model. Defaults to (256, 256).\n",
        "        \"\"\"\n",
        "        super(NeuralNet, self).__init__()\n",
        "\n",
        "        # instantiating the base model and freezing it's weights\n",
        "        self.base_model = self.select_model(base_model, image_shape)\n",
        "        self.base_model.trainable=False\n",
        "\n",
        "        # The layers below form the classification head\n",
        "        self.conv1 = layers.Conv1D(3, 12, 6, activation=\"relu\")\n",
        "        self.pool1 = layers.MaxPool1D(3,3)\n",
        "        self.bn1 = layers.BatchNormalization()\n",
        "        self.conv2 = layers.Conv1D(3, 6, 3, activation=\"relu\")\n",
        "        self.pool2 = layers.MaxPool1D(3,3)\n",
        "        self.bn2 = layers.BatchNormalization()\n",
        "        self.output_layer = layers.Dense(10, activation=None)\n",
        "\n",
        "    @staticmethod\n",
        "    def select_model(name, image_shape):\n",
        "        \"\"\"Selects the pretrained model to be used\n",
        "\n",
        "        Args:\n",
        "            name (str): name of the pretrained model to use\n",
        "            image_shape (tuple): input size for the pretrained model\n",
        "\n",
        "        Returns:\n",
        "            tf.keras.Model: Base model from tensorflow\n",
        "        \"\"\"\n",
        "\n",
        "        image_shape = list(image_shape)\n",
        "        image_shape.append(3)\n",
        "\n",
        "        INPUT_SHAPE = tuple(image_shape)\n",
        "\n",
        "        if name==\"InceptionV3\":\n",
        "            return tf.keras.applications.InceptionV3(include_top=False, input_shape=INPUT_SHAPE, weights='imagenet')\n",
        "        elif name==\"InceptionResNetV2\":\n",
        "            return tf.keras.applications.InceptionResNetV2(include_top=False, input_shape=INPUT_SHAPE, weights='imagenet')\n",
        "        elif name==\"ResNet50\":\n",
        "            return tf.keras.applications.ResNet50(include_top=False, input_shape=INPUT_SHAPE, weights='imagenet')\n",
        "        elif name==\"Xception\":\n",
        "            return tf.keras.applications.Xception(include_top=False, input_shape=INPUT_SHAPE, weights='imagenet')\n",
        "\n",
        "    def call(self, x):\n",
        "        \"\"\"Performs forward pass for the model\n",
        "\n",
        "        Args:\n",
        "            x (tf.tensor): input for the model\n",
        "\n",
        "        Returns:\n",
        "            tf.tensor: output of the model\n",
        "        \"\"\"\n",
        "        x = layers.Flatten()(self.base_model(x))\n",
        "\n",
        "        x = tf.expand_dims(x, -1)\n",
        "        x = self.bn1(self.pool1(self.conv1(x)))\n",
        "        x = self.bn2(self.pool2(self.conv2(x)))\n",
        "        x = layers.Flatten()(x)\n",
        "\n",
        "        return self.output_layer(x)"
      ],
      "metadata": {
        "id": "59keOcg4eXQD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This is the main function to use to train/fine-tune the model using wandb runs\n",
        "def train_with_wandb(image_shape=(256, 256), epochs=30, fine_tune_epochs=10):\n",
        "\n",
        "    config_defaults = {\"base_model\": \"InceptionV3\"}\n",
        "\n",
        "    wandb.init(config=config_defaults, project=\"cs6910-assignment2\", magic=True)\n",
        "\n",
        "    ## 1. Data loading\n",
        "    print(\"1. Loading the dataset ...\\n\")\n",
        "    train_ds, val_ds = load_data(image_shape)\n",
        "\n",
        "    ## 2. Initializing the model\n",
        "    print(\"2. Initializing the model ...\\n\")\n",
        "    model = NeuralNet(wandb.config.base_model, image_shape=image_shape)\n",
        "\n",
        "    ## 3. Compiling the model\n",
        "    base_learning_rate = 0.0002\n",
        "\n",
        "    print(\"3. Compiling the model ...\\n\")\n",
        "    model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=base_learning_rate),\n",
        "                  loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    ## 4. Fitting the model\n",
        "    print(\"4. Fitting the model ...\\n\")\n",
        "    model.fit(train_ds,\n",
        "              validation_data=val_ds,\n",
        "              epochs=epochs,\n",
        "              callbacks=[WandbCallback()])\n",
        "    print(\"Model trained successfully!!\\n\")\n",
        "\n",
        "    ## 5. Fine tuning the model\n",
        "    to_tune_defaults = {\n",
        "        \"InceptionV3\": 55,\n",
        "        \"InceptionResNetV2\": 55,\n",
        "        \"ResNet50\": 50,\n",
        "        \"Xception\": 50\n",
        "    }\n",
        "\n",
        "    model.base_model.trainable = True\n",
        "    print(f\"Total layers in base model is {len(model.base_model.layers)}\\n\")\n",
        "\n",
        "    fine_tune_at = len(model.base_model.layers) - to_tune_defaults[wandb.config.base_model]\n",
        "\n",
        "    for layer in model.base_model.layers[:fine_tune_at]:\n",
        "        layer.trainable =  False\n",
        "\n",
        "    model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=base_learning_rate/10),\n",
        "                  loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    print(\"Fine tuning the model ...\\n\")\n",
        "    model.fit(train_ds,\n",
        "              validation_data=val_ds,\n",
        "              epochs=fine_tune_epochs,\n",
        "              callbacks=[WandbCallback()])\n",
        "    print(\"Model tuned successfully!!\\n\")\n"
      ],
      "metadata": {
        "id": "BgDW1x0geXSJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CphZ1MKyeXU6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}